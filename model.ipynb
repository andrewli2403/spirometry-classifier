{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96e222a-b7bb-4b34-b280-fa446cc952eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T01:16:50.286632Z",
     "iopub.status.busy": "2023-08-15T01:16:50.286247Z",
     "iopub.status.idle": "2023-08-15T01:16:50.690043Z",
     "shell.execute_reply": "2023-08-15T01:16:50.689077Z",
     "shell.execute_reply.started": "2023-08-15T01:16:50.286607Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 08:46:12.229136: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8829ffcb-5b71-4280-b728-b92aef5da985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SPATTYPE</th>\n",
       "      <th>SPAMANU</th>\n",
       "      <th>SPAFACT</th>\n",
       "      <th>SPAPOS</th>\n",
       "      <th>SPAPLAT</th>\n",
       "      <th>SPAACC</th>\n",
       "      <th>SPAQEFF</th>\n",
       "      <th>SPXPTS</th>\n",
       "      <th>SPXRAW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66208</td>\n",
       "      <td>Pre</td>\n",
       "      <td>3</td>\n",
       "      <td>1.080</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>A</td>\n",
       "      <td>1026</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62541</td>\n",
       "      <td>Pre</td>\n",
       "      <td>7</td>\n",
       "      <td>1.080</td>\n",
       "      <td>Standing</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>C</td>\n",
       "      <td>452</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71628</td>\n",
       "      <td>Pre</td>\n",
       "      <td>2</td>\n",
       "      <td>1.091</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>A</td>\n",
       "      <td>1081</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64470</td>\n",
       "      <td>Pre</td>\n",
       "      <td>1</td>\n",
       "      <td>1.079</td>\n",
       "      <td>Standing</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>388</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65928</td>\n",
       "      <td>Pre</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085</td>\n",
       "      <td>Standing</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>C</td>\n",
       "      <td>179</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEQN SPATTYPE  SPAMANU  SPAFACT    SPAPOS SPAPLAT SPAACC SPAQEFF  SPXPTS  \\\n",
       "0  66208      Pre        3    1.080  Standing       Y      Y       A    1026   \n",
       "1  62541      Pre        7    1.080  Standing       N      Y       C     452   \n",
       "2  71628      Pre        2    1.091  Standing       Y      Y       A    1081   \n",
       "3  64470      Pre        1    1.079  Standing       N      N       D     388   \n",
       "4  65928      Pre        1    1.085  Standing       N      Y       C     179   \n",
       "\n",
       "                                              SPXRAW  \n",
       "0  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "1  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "2  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "3  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "4  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cdc_sample.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431ff8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn raw data curve into list of integers\n",
    "df[\"SPXRAW\"] = df.apply(lambda row : np.array([int(num) for num in row['SPXRAW'].split(\",\")]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa888fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of vector to same SPXRAW length\n",
    "x = df[\"SPXRAW\"].to_numpy()\n",
    "n_steps = max([trial.shape[0] for trial in x])\n",
    "\n",
    "# Pad 0s in the back\n",
    "#x_padded = np.array([np.pad(trial, (0, n_steps - trial.shape[0]), mode='constant') for trial in x])\n",
    "\n",
    "# Pad 0s in front and back\n",
    "x_padded = np.array([np.pad(trial, \n",
    "                            ((n_steps-trial.shape[0])//2, (n_steps - trial.shape[0]) - (n_steps-trial.shape[0])//2), \n",
    "                             mode='constant') for trial in x])\n",
    "\n",
    "# Pad 0x in the front\n",
    "#x_padded = np.array([np.pad(trial, (n_steps - trial.shape[0], 0), mode='constant') for trial in x])\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()  # initialize the scaler\n",
    "x_scaled = scaler.fit_transform(x_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f118b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical values\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['SPAQEFF'])\n",
    "\n",
    "#convert numbered classes to be treated as categorical variable\n",
    "n_classes = len(np.unique(y))\n",
    "#y_categorical = to_categorical(y, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eddfd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Seed\n",
    "random_seed = 204\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39508555",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.3, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db33498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c86b22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af48571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 2044, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 2044, 1)     2           ['input_2[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 2044, 1)     7169        ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 2044, 1)      0           ['multi_head_attention_6[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 2044, 1)     0           ['dropout_13[0][0]',             \n",
      " ambda)                                                           'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_12[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 2044, 4)      8           ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 2044, 4)      0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 2044, 1)      5           ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 2044, 1)     0           ['conv1d_13[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_13[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 2044, 1)     7169        ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 2044, 1)      0           ['multi_head_attention_7[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 2044, 1)     0           ['dropout_15[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_14[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 2044, 4)      8           ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 2044, 4)      0           ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 2044, 1)      5           ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 2044, 1)     0           ['conv1d_15[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_15[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 2044, 1)     7169        ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 2044, 1)      0           ['multi_head_attention_8[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 2044, 1)     0           ['dropout_17[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 2044, 4)      8           ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 2044, 4)      0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 2044, 1)      5           ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 2044, 1)     0           ['conv1d_17[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 2044, 1)     7169        ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 2044, 1)      0           ['multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 2044, 1)     0           ['dropout_19[0][0]',             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ambda)                                                           'tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 2044, 4)      8           ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 2044, 4)      0           ['conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 2044, 1)      5           ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 2044, 1)     0           ['conv1d_19[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_19[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 2044, 1)     7169        ['layer_normalization_20[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 2044, 1)      0           ['multi_head_attention_10[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 2044, 1)     0           ['dropout_21[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 2044, 4)      8           ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 2044, 4)      0           ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 2044, 1)      5           ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 2044, 1)     0           ['conv1d_21[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 2044, 1)     7169        ['layer_normalization_22[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 2044, 1)      0           ['multi_head_attention_11[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 2044, 1)     0           ['dropout_23[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 2044, 1)     2           ['tf.__operators__.add_22[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 2044, 4)      8           ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 2044, 4)      0           ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 2044, 1)      5           ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 2044, 1)     0           ['conv1d_23[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 2044)        0           ['tf.__operators__.add_23[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          261760      ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4)            516         ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 305,392\n",
      "Trainable params: 305,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 19:10:37.033739: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-08-19 19:10:37.634386: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-19 19:10:37.634996: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-19 19:10:37.635036: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-08-19 19:10:37.635723: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-19 19:10:37.635812: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 809s 1s/step - loss: 1.1532 - sparse_categorical_accuracy: 0.5280 - val_loss: 1.1582 - val_sparse_categorical_accuracy: 0.5157\n",
      "Epoch 2/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 1.0854 - sparse_categorical_accuracy: 0.5546 - val_loss: 1.0326 - val_sparse_categorical_accuracy: 0.5664\n",
      "Epoch 3/150\n",
      "700/700 [==============================] - 814s 1s/step - loss: 1.0374 - sparse_categorical_accuracy: 0.5821 - val_loss: 0.9902 - val_sparse_categorical_accuracy: 0.5886\n",
      "Epoch 4/150\n",
      "700/700 [==============================] - 813s 1s/step - loss: 0.9965 - sparse_categorical_accuracy: 0.6037 - val_loss: 0.9698 - val_sparse_categorical_accuracy: 0.6043\n",
      "Epoch 5/150\n",
      "700/700 [==============================] - 813s 1s/step - loss: 0.9668 - sparse_categorical_accuracy: 0.6145 - val_loss: 0.9286 - val_sparse_categorical_accuracy: 0.6450\n",
      "Epoch 6/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.9307 - sparse_categorical_accuracy: 0.6377 - val_loss: 0.9244 - val_sparse_categorical_accuracy: 0.6379\n",
      "Epoch 7/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.9047 - sparse_categorical_accuracy: 0.6541 - val_loss: 0.8999 - val_sparse_categorical_accuracy: 0.6486\n",
      "Epoch 8/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.8949 - sparse_categorical_accuracy: 0.6609 - val_loss: 0.8839 - val_sparse_categorical_accuracy: 0.6607\n",
      "Epoch 9/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.8749 - sparse_categorical_accuracy: 0.6712 - val_loss: 0.8654 - val_sparse_categorical_accuracy: 0.6636\n",
      "Epoch 10/150\n",
      "700/700 [==============================] - 807s 1s/step - loss: 0.8586 - sparse_categorical_accuracy: 0.6796 - val_loss: 0.8644 - val_sparse_categorical_accuracy: 0.6600\n",
      "Epoch 11/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.8468 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.8528 - val_sparse_categorical_accuracy: 0.6686\n",
      "Epoch 12/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.8311 - sparse_categorical_accuracy: 0.6907 - val_loss: 0.8455 - val_sparse_categorical_accuracy: 0.6664\n",
      "Epoch 13/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.8261 - sparse_categorical_accuracy: 0.6893 - val_loss: 0.8322 - val_sparse_categorical_accuracy: 0.6843\n",
      "Epoch 14/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.8098 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.8372 - val_sparse_categorical_accuracy: 0.6907\n",
      "Epoch 15/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.8024 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.8428 - val_sparse_categorical_accuracy: 0.7129\n",
      "Epoch 16/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.7854 - sparse_categorical_accuracy: 0.7120 - val_loss: 0.8071 - val_sparse_categorical_accuracy: 0.6993\n",
      "Epoch 17/150\n",
      "700/700 [==============================] - 808s 1s/step - loss: 0.7839 - sparse_categorical_accuracy: 0.7105 - val_loss: 0.8056 - val_sparse_categorical_accuracy: 0.6950\n",
      "Epoch 18/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.7781 - sparse_categorical_accuracy: 0.7132 - val_loss: 0.7990 - val_sparse_categorical_accuracy: 0.7036\n",
      "Epoch 19/150\n",
      "700/700 [==============================] - 807s 1s/step - loss: 0.7723 - sparse_categorical_accuracy: 0.7150 - val_loss: 0.7860 - val_sparse_categorical_accuracy: 0.7057\n",
      "Epoch 20/150\n",
      "700/700 [==============================] - 804s 1s/step - loss: 0.7588 - sparse_categorical_accuracy: 0.7230 - val_loss: 0.7780 - val_sparse_categorical_accuracy: 0.7121\n",
      "Epoch 21/150\n",
      "700/700 [==============================] - 800s 1s/step - loss: 0.7591 - sparse_categorical_accuracy: 0.7271 - val_loss: 0.7777 - val_sparse_categorical_accuracy: 0.7114\n",
      "Epoch 22/150\n",
      "700/700 [==============================] - 799s 1s/step - loss: 0.7556 - sparse_categorical_accuracy: 0.7220 - val_loss: 0.8104 - val_sparse_categorical_accuracy: 0.6979\n",
      "Epoch 23/150\n",
      "700/700 [==============================] - 801s 1s/step - loss: 0.7438 - sparse_categorical_accuracy: 0.7279 - val_loss: 0.7760 - val_sparse_categorical_accuracy: 0.7043\n",
      "Epoch 24/150\n",
      "700/700 [==============================] - 807s 1s/step - loss: 0.7342 - sparse_categorical_accuracy: 0.7298 - val_loss: 0.7609 - val_sparse_categorical_accuracy: 0.7229\n",
      "Epoch 25/150\n",
      "700/700 [==============================] - 804s 1s/step - loss: 0.7361 - sparse_categorical_accuracy: 0.7321 - val_loss: 0.7679 - val_sparse_categorical_accuracy: 0.7143\n",
      "Epoch 26/150\n",
      "700/700 [==============================] - 808s 1s/step - loss: 0.7303 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.7562 - val_sparse_categorical_accuracy: 0.7343\n",
      "Epoch 27/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 0.7307 - sparse_categorical_accuracy: 0.7336 - val_loss: 0.7597 - val_sparse_categorical_accuracy: 0.7229\n",
      "Epoch 28/150\n",
      "700/700 [==============================] - 818s 1s/step - loss: 0.7250 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.7733 - val_sparse_categorical_accuracy: 0.6971\n",
      "Epoch 29/150\n",
      "700/700 [==============================] - 821s 1s/step - loss: 0.7249 - sparse_categorical_accuracy: 0.7405 - val_loss: 0.7622 - val_sparse_categorical_accuracy: 0.7214\n",
      "Epoch 30/150\n",
      "700/700 [==============================] - 813s 1s/step - loss: 0.7161 - sparse_categorical_accuracy: 0.7359 - val_loss: 0.7594 - val_sparse_categorical_accuracy: 0.7179\n",
      "Epoch 31/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.7135 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.7539 - val_sparse_categorical_accuracy: 0.7243\n",
      "Epoch 32/150\n",
      "700/700 [==============================] - 814s 1s/step - loss: 0.7139 - sparse_categorical_accuracy: 0.7407 - val_loss: 0.7614 - val_sparse_categorical_accuracy: 0.7079\n",
      "Epoch 33/150\n",
      "700/700 [==============================] - 811s 1s/step - loss: 0.7067 - sparse_categorical_accuracy: 0.7436 - val_loss: 0.7447 - val_sparse_categorical_accuracy: 0.7250\n",
      "Epoch 34/150\n",
      "700/700 [==============================] - 807s 1s/step - loss: 0.7072 - sparse_categorical_accuracy: 0.7405 - val_loss: 0.7508 - val_sparse_categorical_accuracy: 0.7386\n",
      "Epoch 35/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.7081 - sparse_categorical_accuracy: 0.7430 - val_loss: 0.7430 - val_sparse_categorical_accuracy: 0.7207\n",
      "Epoch 36/150\n",
      "700/700 [==============================] - 807s 1s/step - loss: 0.6961 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.7400 - val_sparse_categorical_accuracy: 0.7343\n",
      "Epoch 37/150\n",
      "700/700 [==============================] - 807s 1s/step - loss: 0.6974 - sparse_categorical_accuracy: 0.7461 - val_loss: 0.7441 - val_sparse_categorical_accuracy: 0.7229\n",
      "Epoch 38/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 0.6975 - sparse_categorical_accuracy: 0.7454 - val_loss: 0.7492 - val_sparse_categorical_accuracy: 0.7200\n",
      "Epoch 39/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.7014 - sparse_categorical_accuracy: 0.7446 - val_loss: 0.7483 - val_sparse_categorical_accuracy: 0.7179\n",
      "Epoch 40/150\n",
      "700/700 [==============================] - 814s 1s/step - loss: 0.6935 - sparse_categorical_accuracy: 0.7455 - val_loss: 0.7291 - val_sparse_categorical_accuracy: 0.7336\n",
      "Epoch 41/150\n",
      "700/700 [==============================] - 813s 1s/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7399 - val_sparse_categorical_accuracy: 0.7171\n",
      "Epoch 42/150\n",
      "700/700 [==============================] - 815s 1s/step - loss: 0.6926 - sparse_categorical_accuracy: 0.7509 - val_loss: 0.7386 - val_sparse_categorical_accuracy: 0.7357\n",
      "Epoch 43/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.6830 - sparse_categorical_accuracy: 0.7464 - val_loss: 0.7256 - val_sparse_categorical_accuracy: 0.7371\n",
      "Epoch 44/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 0.6796 - sparse_categorical_accuracy: 0.7461 - val_loss: 0.7222 - val_sparse_categorical_accuracy: 0.7371\n",
      "Epoch 45/150\n",
      "700/700 [==============================] - 814s 1s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.7224 - val_sparse_categorical_accuracy: 0.7471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.7504 - val_loss: 0.7282 - val_sparse_categorical_accuracy: 0.7421\n",
      "Epoch 47/150\n",
      "700/700 [==============================] - 811s 1s/step - loss: 0.6781 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.7220 - val_sparse_categorical_accuracy: 0.7329\n",
      "Epoch 48/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 0.6603 - sparse_categorical_accuracy: 0.7580 - val_loss: 0.7266 - val_sparse_categorical_accuracy: 0.7286\n",
      "Epoch 49/150\n",
      "700/700 [==============================] - 807s 1s/step - loss: 0.6617 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.7235 - val_sparse_categorical_accuracy: 0.7379\n",
      "Epoch 50/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.6640 - sparse_categorical_accuracy: 0.7611 - val_loss: 0.7275 - val_sparse_categorical_accuracy: 0.7429\n",
      "Epoch 51/150\n",
      "700/700 [==============================] - 816s 1s/step - loss: 0.6611 - sparse_categorical_accuracy: 0.7620 - val_loss: 0.7225 - val_sparse_categorical_accuracy: 0.7286\n",
      "Epoch 52/150\n",
      "700/700 [==============================] - 811s 1s/step - loss: 0.6627 - sparse_categorical_accuracy: 0.7589 - val_loss: 0.7177 - val_sparse_categorical_accuracy: 0.7321\n",
      "Epoch 53/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 0.6645 - sparse_categorical_accuracy: 0.7596 - val_loss: 0.7136 - val_sparse_categorical_accuracy: 0.7357\n",
      "Epoch 54/150\n",
      "700/700 [==============================] - 817s 1s/step - loss: 0.6601 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.7075 - val_sparse_categorical_accuracy: 0.7500\n",
      "Epoch 55/150\n",
      "700/700 [==============================] - 817s 1s/step - loss: 0.6503 - sparse_categorical_accuracy: 0.7616 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.7393\n",
      "Epoch 56/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.6508 - sparse_categorical_accuracy: 0.7648 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.7379\n",
      "Epoch 57/150\n",
      "700/700 [==============================] - 820s 1s/step - loss: 0.6480 - sparse_categorical_accuracy: 0.7663 - val_loss: 0.7086 - val_sparse_categorical_accuracy: 0.7464\n",
      "Epoch 58/150\n",
      "700/700 [==============================] - 811s 1s/step - loss: 0.6503 - sparse_categorical_accuracy: 0.7623 - val_loss: 0.7204 - val_sparse_categorical_accuracy: 0.7300\n",
      "Epoch 59/150\n",
      "700/700 [==============================] - 811s 1s/step - loss: 0.6429 - sparse_categorical_accuracy: 0.7648 - val_loss: 0.7147 - val_sparse_categorical_accuracy: 0.7414\n",
      "Epoch 60/150\n",
      "700/700 [==============================] - 814s 1s/step - loss: 0.6428 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.7082 - val_sparse_categorical_accuracy: 0.7471\n",
      "Epoch 61/150\n",
      "700/700 [==============================] - 818s 1s/step - loss: 0.6487 - sparse_categorical_accuracy: 0.7641 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.7400\n",
      "Epoch 62/150\n",
      "700/700 [==============================] - 813s 1s/step - loss: 0.6371 - sparse_categorical_accuracy: 0.7652 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.7407\n",
      "Epoch 63/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.6347 - sparse_categorical_accuracy: 0.7704 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.7486\n",
      "Epoch 64/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.6390 - sparse_categorical_accuracy: 0.7739 - val_loss: 0.7093 - val_sparse_categorical_accuracy: 0.7386\n",
      "Epoch 65/150\n",
      "700/700 [==============================] - 806s 1s/step - loss: 0.6263 - sparse_categorical_accuracy: 0.7720 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.7521\n",
      "Epoch 66/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.6238 - sparse_categorical_accuracy: 0.7763 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.7507\n",
      "Epoch 67/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 0.6281 - sparse_categorical_accuracy: 0.7713 - val_loss: 0.7152 - val_sparse_categorical_accuracy: 0.7364\n",
      "Epoch 68/150\n",
      "700/700 [==============================] - 817s 1s/step - loss: 0.6344 - sparse_categorical_accuracy: 0.7713 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.7429\n",
      "Epoch 69/150\n",
      "700/700 [==============================] - 811s 1s/step - loss: 0.6282 - sparse_categorical_accuracy: 0.7745 - val_loss: 0.7053 - val_sparse_categorical_accuracy: 0.7479\n",
      "Epoch 70/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 0.6210 - sparse_categorical_accuracy: 0.7764 - val_loss: 0.6898 - val_sparse_categorical_accuracy: 0.7536\n",
      "Epoch 71/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.6185 - sparse_categorical_accuracy: 0.7804 - val_loss: 0.7304 - val_sparse_categorical_accuracy: 0.7243\n",
      "Epoch 72/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.6228 - sparse_categorical_accuracy: 0.7732 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.7557\n",
      "Epoch 73/150\n",
      "700/700 [==============================] - 811s 1s/step - loss: 0.6151 - sparse_categorical_accuracy: 0.7804 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.7536\n",
      "Epoch 74/150\n",
      "700/700 [==============================] - 816s 1s/step - loss: 0.6188 - sparse_categorical_accuracy: 0.7705 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.7436\n",
      "Epoch 75/150\n",
      "700/700 [==============================] - 810s 1s/step - loss: 0.6143 - sparse_categorical_accuracy: 0.7793 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.7507\n",
      "Epoch 76/150\n",
      "700/700 [==============================] - 814s 1s/step - loss: 0.6086 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.7357\n",
      "Epoch 77/150\n",
      "700/700 [==============================] - 811s 1s/step - loss: 0.6142 - sparse_categorical_accuracy: 0.7789 - val_loss: 0.7009 - val_sparse_categorical_accuracy: 0.7407\n",
      "Epoch 78/150\n",
      "700/700 [==============================] - 813s 1s/step - loss: 0.6056 - sparse_categorical_accuracy: 0.7843 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.7550\n",
      "Epoch 79/150\n",
      "700/700 [==============================] - 813s 1s/step - loss: 0.6113 - sparse_categorical_accuracy: 0.7796 - val_loss: 0.7042 - val_sparse_categorical_accuracy: 0.7443\n",
      "Epoch 80/150\n",
      "700/700 [==============================] - 817s 1s/step - loss: 0.6060 - sparse_categorical_accuracy: 0.7812 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.7386\n",
      "Epoch 81/150\n",
      "700/700 [==============================] - 814s 1s/step - loss: 0.6032 - sparse_categorical_accuracy: 0.7862 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.7514\n",
      "Epoch 82/150\n",
      "700/700 [==============================] - 811s 1s/step - loss: 0.6018 - sparse_categorical_accuracy: 0.7843 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.7564\n",
      "Epoch 83/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.5952 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.7521\n",
      "Epoch 84/150\n",
      "700/700 [==============================] - 809s 1s/step - loss: 0.5955 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.7493\n",
      "Epoch 85/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 0.5928 - sparse_categorical_accuracy: 0.7861 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.7543\n",
      "Epoch 86/150\n",
      "700/700 [==============================] - 812s 1s/step - loss: 0.5889 - sparse_categorical_accuracy: 0.7898 - val_loss: 0.6794 - val_sparse_categorical_accuracy: 0.7629\n",
      "Epoch 87/150\n",
      "700/700 [==============================] - 813s 1s/step - loss: 0.5837 - sparse_categorical_accuracy: 0.7871 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.7493\n",
      "Epoch 88/150\n",
      "700/700 [==============================] - 814s 1s/step - loss: 0.5866 - sparse_categorical_accuracy: 0.7868 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.7457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27a45f1d00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=6,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    #optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    optimizer=keras.optimizers.legacy.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "max_epochs = 150\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=max_epochs,\n",
    "    batch_size=8,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de2ced3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_6_88.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(file_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "file_path = 'model_6_88.keras'\n",
    "model.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bebc2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 08:47:31.314466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 08:47:31.320201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 08:47:31.320480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 08:47:31.321013: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 08:47:31.321380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 08:47:31.321621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 08:47:31.321815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 08:47:31.983699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 08:47:31.983994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 08:47:31.984190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 08:47:31.984379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13794 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 08:47:36.470320: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-08-21 08:47:37.096897: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-21 08:47:37.100745: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-21 08:47:37.100787: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-08-21 08:47:37.104277: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-21 08:47:37.104402: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 821s 1s/step - loss: 0.7856 - sparse_categorical_accuracy: 0.7121 - val_loss: 0.7707 - val_sparse_categorical_accuracy: 0.7129\n",
      "Epoch 2/80\n",
      "700/700 [==============================] - 820s 1s/step - loss: 0.7860 - sparse_categorical_accuracy: 0.7121 - val_loss: 0.7711 - val_sparse_categorical_accuracy: 0.7121\n",
      "Epoch 3/80\n",
      "700/700 [==============================] - 820s 1s/step - loss: 0.7850 - sparse_categorical_accuracy: 0.7120 - val_loss: 0.7692 - val_sparse_categorical_accuracy: 0.7150\n",
      "Epoch 4/80\n",
      "700/700 [==============================] - 821s 1s/step - loss: 0.7751 - sparse_categorical_accuracy: 0.7155 - val_loss: 0.7617 - val_sparse_categorical_accuracy: 0.7121\n",
      "Epoch 5/80\n",
      "700/700 [==============================] - 820s 1s/step - loss: 0.7846 - sparse_categorical_accuracy: 0.7143 - val_loss: 0.7689 - val_sparse_categorical_accuracy: 0.7157\n",
      "Epoch 6/80\n",
      "700/700 [==============================] - 820s 1s/step - loss: 0.7790 - sparse_categorical_accuracy: 0.7141 - val_loss: 0.7658 - val_sparse_categorical_accuracy: 0.7186\n",
      "Epoch 7/80\n",
      "700/700 [==============================] - 826s 1s/step - loss: 0.7818 - sparse_categorical_accuracy: 0.7152 - val_loss: 0.7732 - val_sparse_categorical_accuracy: 0.7150\n",
      "Epoch 8/80\n",
      "700/700 [==============================] - 821s 1s/step - loss: 0.7819 - sparse_categorical_accuracy: 0.7171 - val_loss: 0.7671 - val_sparse_categorical_accuracy: 0.7100\n",
      "Epoch 9/80\n",
      "700/700 [==============================] - 823s 1s/step - loss: 0.7820 - sparse_categorical_accuracy: 0.7143 - val_loss: 0.7632 - val_sparse_categorical_accuracy: 0.7164\n",
      "Epoch 10/80\n",
      "700/700 [==============================] - 825s 1s/step - loss: 0.7751 - sparse_categorical_accuracy: 0.7179 - val_loss: 0.7633 - val_sparse_categorical_accuracy: 0.7129\n",
      "Epoch 11/80\n",
      "700/700 [==============================] - 825s 1s/step - loss: 0.7766 - sparse_categorical_accuracy: 0.7170 - val_loss: 0.7617 - val_sparse_categorical_accuracy: 0.7107\n",
      "Epoch 12/80\n",
      "700/700 [==============================] - 822s 1s/step - loss: 0.7764 - sparse_categorical_accuracy: 0.7159 - val_loss: 0.7680 - val_sparse_categorical_accuracy: 0.7171\n",
      "Epoch 13/80\n",
      "700/700 [==============================] - 822s 1s/step - loss: 0.7778 - sparse_categorical_accuracy: 0.7163 - val_loss: 0.7696 - val_sparse_categorical_accuracy: 0.7171\n",
      "Epoch 14/80\n",
      "700/700 [==============================] - 820s 1s/step - loss: 0.7735 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.7634 - val_sparse_categorical_accuracy: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc805fa8190>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load again from certain epoch\n",
    "file_path = './split/model_6_70.keras'\n",
    "model = load_model(file_path)\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=80,\n",
    "    batch_size=8,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4812ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'model_6_150.keras'\n",
    "model.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723641c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_93.keras')\n",
    "\n",
    "# Evaluate the performance of the model on the testing set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189abad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
